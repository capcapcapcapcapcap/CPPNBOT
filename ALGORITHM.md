# 原型网络跨域机器人检测算法详解

## 1. 问题背景

**目标**: 在源域 (Twibot-20) 训练模型，迁移到目标域 (Misbot) 进行机器人检测

**挑战**: 
- 不同平台的机器人行为模式不同
- 目标域标注数据稀缺
- 传统监督学习难以跨域泛化

**解决方案**: 原型网络 (Prototypical Network) + 元学习 (Meta-Learning)

---

## 2. 整体架构

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         原型网络跨域机器人检测                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐    ┌──────────────────┐    ┌─────────────────────┐    │
│  │   源域数据   │───▶│   元训练 (Train)  │───▶│  预训练模型 (.pt)   │    │
│  │  Twibot-20  │    │   100 episodes   │    │   best_model.pt    │    │
│  └─────────────┘    └──────────────────┘    └──────────┬──────────┘    │
│                                                        │               │
│                                                        ▼               │
│  ┌─────────────┐    ┌──────────────────┐    ┌─────────────────────┐    │
│  │  目标域数据  │───▶│  小样本适应 (Eval) │◀───│   冻结编码器权重     │    │
│  │   Misbot    │    │   K-shot 分类    │    │   Few-shot Adapt   │    │
│  └─────────────┘    └──────────────────┘    └─────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 数据流与特征

### 3.1 输入特征

```
用户特征
├── 数值特征 (8维): followers, following, tweets, listed, age, ratio, username_len, desc_len
├── 分类特征 (5维): verified, protected, default_avatar, has_url, has_location
├── 文本特征 (可选): description + tweets
└── 图特征 (可选): 社交网络结构
```

### 3.2 多模态编码器

```
┌─────────────────────────────────────────────────────────────────┐
│                    MultiModalEncoder                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  数值特征 [batch, 8]                                            │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────┐                           │
│  │     NumericalEncoder            │                           │
│  │  Linear(8→32) + ReLU            │                           │
│  │  Linear(32→64) + ReLU           │                           │
│  │  LayerNorm(64)                  │                           │
│  └─────────────────┬───────────────┘                           │
│                    │ [batch, 64]                                │
│                    │                                            │
│  分类特征 [batch, 5]                                            │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────┐                           │
│  │     CategoricalEncoder          │                           │
│  │  Embedding(2, 16) × 5           │                           │
│  │  Concat → [batch, 80]           │                           │
│  │  Linear(80→32)                  │                           │
│  └─────────────────┬───────────────┘                           │
│                    │ [batch, 32]                                │
│                    │                                            │
│  文本 (可选)                                                     │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────┐                           │
│  │     TextEncoder (XLM-RoBERTa)   │                           │
│  │  Tokenize → Encode → Pool       │                           │
│  │  Linear(768→256)                │                           │
│  └─────────────────┬───────────────┘                           │
│                    │ [batch, 256]                               │
│                    │                                            │
│  图结构 (可选)                                                   │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────┐                           │
│  │     GraphEncoder (GAT)          │                           │
│  │  GATConv × 2 layers             │                           │
│  │  Multi-head attention           │                           │
│  └─────────────────┬───────────────┘                           │
│                    │ [batch, 128]                               │
│                    │                                            │
│                    ▼                                            │
│              ┌───────────────┐                                  │
│              │ AttentionFusion│                                 │
│              │ 学习模态权重    │                                 │
│              │ 加权融合        │                                 │
│              └───────┬───────┘                                  │
│                      │ [batch, 256]                             │
│                      ▼                                          │
│                用户嵌入向量                                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 4. 原型网络算法

### 4.1 Episode 结构 (N-way K-shot)

```
┌─────────────────────────────────────────────────────────────────┐
│                    Episode (2-way 10-shot)                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Support Set (用于计算原型)                                      │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  Human (Class 0): 10 samples ──▶ 计算均值 ──▶ Prototype₀ │   │
│  │  Bot   (Class 1): 10 samples ──▶ 计算均值 ──▶ Prototype₁ │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Query Set (用于分类评估)                                        │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  Human (Class 0): 15 samples ──▶ 计算到原型的距离         │   │
│  │  Bot   (Class 1): 15 samples ──▶ 分类 + 计算损失          │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 原型计算与分类

```
┌─────────────────────────────────────────────────────────────────┐
│                    原型网络前向传播                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Step 1: 编码                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  Support samples ──▶ Encoder ──▶ support_embeddings     │   │
│  │  Query samples   ──▶ Encoder ──▶ query_embeddings       │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Step 2: 计算原型 (类中心)                                       │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │  Prototype_c = mean(support_embeddings[label == c])     │   │
│  │                                                         │   │
│  │  ┌───────────────────────────────────────────────────┐ │   │
│  │  │     Human 样本嵌入                                 │ │   │
│  │  │     ○  ○  ○  ○  ○  ○  ○  ○  ○  ○                 │ │   │
│  │  │              ↓ 均值                                │ │   │
│  │  │              ●  Prototype₀ (Human)                │ │   │
│  │  └───────────────────────────────────────────────────┘ │   │
│  │                                                         │   │
│  │  ┌───────────────────────────────────────────────────┐ │   │
│  │  │     Bot 样本嵌入                                   │ │   │
│  │  │     △  △  △  △  △  △  △  △  △  △                 │ │   │
│  │  │              ↓ 均值                                │ │   │
│  │  │              ▲  Prototype₁ (Bot)                  │ │   │
│  │  └───────────────────────────────────────────────────┘ │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Step 3: 距离计算                                               │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │  欧氏距离: d(q, p) = ||q - p||²                         │   │
│  │  余弦距离: d(q, p) = 1 - cos(q, p)                      │   │
│  │                                                         │   │
│  │       Query                                             │   │
│  │         ◇                                               │   │
│  │        /│\                                              │   │
│  │       / │ \                                             │   │
│  │      /  │  \                                            │   │
│  │     /   │   \                                           │   │
│  │    ●────┼────▲                                          │   │
│  │   P₀   d₀  d₁  P₁                                       │   │
│  │                                                         │   │
│  │  d₀ = distance(query, Prototype₀)                       │   │
│  │  d₁ = distance(query, Prototype₁)                       │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  Step 4: 概率计算 (Softmax)                                     │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │  P(y=c|q) = exp(-d_c) / Σ exp(-d_i)                     │   │
│  │                                                         │   │
│  │  距离越小 → 概率越大                                     │   │
│  │                                                         │   │
│  │  log_probs = log_softmax(-distances)                    │   │
│  │  prediction = argmax(log_probs)                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 5. 训练流程

### 5.1 元训练循环

```
┌─────────────────────────────────────────────────────────────────┐
│                    训练流程 (Meta-Training)                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  for epoch in range(200):                                       │
│      │                                                          │
│      ├──▶ 训练阶段 (100 episodes)                               │
│      │    ┌─────────────────────────────────────────────────┐  │
│      │    │  for episode in range(100):                     │  │
│      │    │      1. 采样 support + query                    │  │
│      │    │      2. 前向传播 → log_probs                    │  │
│      │    │      3. 计算 NLL Loss                           │  │
│      │    │      4. 反向传播 + 更新权重                      │  │
│      │    │      5. 累计 loss, accuracy, f1                 │  │
│      │    └─────────────────────────────────────────────────┘  │
│      │                                                          │
│      ├──▶ 验证阶段 (50 episodes)                                │
│      │    ┌─────────────────────────────────────────────────┐  │
│      │    │  for episode in range(50):                      │  │
│      │    │      1. 采样 support + query (验证集)            │  │
│      │    │      2. 前向传播 (无梯度)                        │  │
│      │    │      3. 计算指标                                 │  │
│      │    └─────────────────────────────────────────────────┘  │
│      │                                                          │
│      ├──▶ 检查改进                                              │
│      │    ┌─────────────────────────────────────────────────┐  │
│      │    │  if val_loss < best_val_loss:                   │  │
│      │    │      best_val_loss = val_loss                   │  │
│      │    │      save_checkpoint("best_model.pt")  ← 保存   │  │
│      │    │      patience_counter = 0                       │  │
│      │    │  else:                                          │  │
│      │    │      patience_counter += 1                      │  │
│      │    └─────────────────────────────────────────────────┘  │
│      │                                                          │
│      └──▶ 早停检查                                              │
│           ┌─────────────────────────────────────────────────┐  │
│           │  if patience_counter >= 10:                     │  │
│           │      break  ← 停止训练                          │  │
│           └─────────────────────────────────────────────────┘  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 5.2 损失函数

```
Loss = NLLLoss(log_probs, true_labels)
     = -Σ log P(y_true | query)

目标: 最小化 query 样本到正确原型的距离
```

### 5.3 多模态训练特性

- **分离学习率**: 文本编码器使用更小的学习率 (1e-5 vs 1e-3)
- **骨干冻结**: 可选择冻结 XLM-RoBERTa 骨干网络
- **注意力融合**: 自动学习各模态的重要性权重

---

## 6. 跨域评估

### 6.1 Few-shot 适应

```
┌─────────────────────────────────────────────────────────────────┐
│                    跨域评估 (Cross-Domain Evaluation)            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  预训练模型 (Twibot-20)                                         │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  冻结编码器权重 (不更新)                                  │   │
│  │  model.eval()                                            │   │
│  └─────────────────────────────────────────────────────────┘   │
│       │                                                         │
│       ▼                                                         │
│  目标域 (Misbot) 评估                                           │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │  K-shot 评估 (K = 1, 5, 10, 20)                         │   │
│  │                                                         │   │
│  │  for k in [1, 5, 10, 20]:                               │   │
│  │      for episode in range(100):                         │   │
│  │          1. 从目标域采样 K 个 support 样本/类            │   │
│  │          2. 计算新的原型 (目标域)                        │   │
│  │          3. 对 query 样本分类                           │   │
│  │          4. 计算 Accuracy, F1, Precision, Recall        │   │
│  │                                                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  关键点: 编码器学会了"如何比较"，而非"记住类别"                   │
│         因此可以用少量目标域样本构建新原型                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 6.2 为什么能跨域？

```
┌─────────────────────────────────────────────────────────────────┐
│                    跨域泛化原理                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  传统监督学习:                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  学习: 特征 → 类别 (固定分类头)                          │   │
│  │  问题: 分类头绑定源域类别分布，难以迁移                   │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  原型网络:                                                       │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  学习: 特征 → 嵌入空间 (度量学习)                        │   │
│  │  分类: 基于距离比较，无固定分类头                         │   │
│  │  优势: 只需少量目标域样本重新计算原型                     │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  嵌入空间可视化:                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                                                         │   │
│  │     源域 (Twibot-20)          目标域 (Misbot)           │   │
│  │                                                         │   │
│  │     ○ ○ ○                      ○ ○                      │   │
│  │       ○ ○ ○                      ○ ○ ○                  │   │
│  │         ●  ← Human原型              ●  ← 新Human原型    │   │
│  │                                                         │   │
│  │                                                         │   │
│  │         ▲  ← Bot原型                ▲  ← 新Bot原型      │   │
│  │       △ △ △                      △ △ △                  │   │
│  │     △ △ △                      △ △                      │   │
│  │                                                         │   │
│  │  编码器将相似用户映射到相近位置，不同类别分开              │   │
│  │  目标域只需少量样本计算新原型即可分类                     │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 7. 配置参数

```yaml
# 模型架构
model:
  # 数值编码器
  num_input_dim: 8        # 数值特征维度
  num_hidden_dim: 32      # 数值编码器隐藏层
  num_output_dim: 64      # 数值编码器输出
  
  # 分类编码器
  cat_num_categories: [2, 2, 2, 2, 2]  # 分类特征类别数
  cat_embedding_dim: 16   # 分类嵌入维度
  cat_output_dim: 32      # 分类编码器输出
  
  # 文本编码器 (可选)
  text_model_name: xlm-roberta-base
  text_output_dim: 256
  text_max_length: 512
  text_freeze_backbone: true
  
  # 图编码器 (可选)
  graph_input_dim: 256
  graph_hidden_dim: 128
  graph_output_dim: 128
  graph_num_heads: 4
  graph_num_layers: 2
  
  # 融合模块
  fusion_output_dim: 256  # 最终嵌入维度
  fusion_dropout: 0.1
  fusion_use_attention: true
  
  # 启用的模态
  enabled_modalities: ['num', 'cat']  # 可选: 'text', 'graph'
  
  # 距离度量
  distance_metric: euclidean  # 或 'cosine'

# 训练配置
training:
  n_way: 2          # 2类分类 (human vs bot)
  k_shot: 10        # 每类10个support样本
  n_query: 15       # 每类15个query样本
  n_episodes_train: 100  # 每epoch训练episodes
  n_episodes_val: 50     # 每epoch验证episodes
  n_epochs: 200     # 最大训练轮数
  learning_rate: 0.001
  text_learning_rate: 0.00001  # 文本编码器学习率
  weight_decay: 0.0001
  patience: 10      # 早停耐心值
```

---

## 8. 运行命令

```bash
# 数据预处理
python preprocess_unified.py --dataset all

# 训练 (源域: Twibot-20)
python experiments/train_source.py --config configs/default.yaml

# 评估 (目标域: Misbot)
python experiments/evaluate_target.py --model-path results/{timestamp}/best_model.pt

# 消融实验
python experiments/train_source.py --config configs/ablation_num_cat.yaml
python experiments/train_source.py --config configs/ablation_num_cat_text.yaml
python experiments/train_source.py --config configs/ablation_all.yaml
```

---

## 9. 参考文献

- Snell, J., Swersky, K., & Zemel, R. (2017). Prototypical Networks for Few-shot Learning. NeurIPS.
